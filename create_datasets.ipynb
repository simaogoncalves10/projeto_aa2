{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5107763",
   "metadata": {},
   "source": [
    " ## **Criação do dataset**\n",
    "\n",
    "Os dados fornecidos para este trabalho estarão no formato JSON e serão disponibilizados a partir da plataforma de conhecimento sobre cancro gástrico desenvolvido no grupo BioSystems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ca7cb",
   "metadata": {},
   "source": [
    "**Aceder à API e analisar a estrutura dos dados**\n",
    "\n",
    "Iniciamos o projeto por aceder á API (https://gcplatform.bio.di.uminho.pt/api/pub/swagger-ui/index.html?configUrl=/api/pub/v3/api-docs/swagger-config#/pageable-publications-controller/findPubmedPubsByQuery) e analisar os dados relativos ao cancro do estômago.\n",
    "\n",
    "Após uma análise verificamos que a estrutura dos objetos era a seguinte:\n",
    "\n",
    "{\n",
    "    id (string)\n",
    "    idGenerator (string)\n",
    "    source (string)\n",
    "    createdDate (string date-time)\n",
    "    lastModifiedDate (string date-time)\n",
    "    title (string)\n",
    "    summary (string)\n",
    "    content (string)\n",
    "    xdbRefs (uniqueItems: true string)\n",
    "    meshTerms (uniqueItems: true string)\n",
    "    keywords (uniqueItems: true string)\n",
    "    \n",
    "}\n",
    "\n",
    "Também verificamos que da estrutura das páginas JSON da API apenas nos interessava o array \"content\", que continha os objetos com a estrutura em cima representada e com a informação que necessitavamos.\n",
    "\n",
    "\n",
    "**Recolher informação da API para um ficheiro json**\n",
    "\n",
    "De seguida, foi necessário recolher a informação importante da API para um ficheiro JSON.\n",
    "Para tal, utilizamos três bibliotecas. A biblioteca **urllib.parse**, para manipularmos o url, a biblioteca **requests**, que é uma biblioteca HTTP necessária para recebermos a informação da API, e, a biblioteca **json**, para manipular os ficheiros json."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-protocol",
   "metadata": {},
   "source": [
    "Posto isto, criamos um loop que efetuas pedidos sobre as 145 páginas existentes na API sobre o cancro do estômago e que coloca, a informação do content de cada página, numa pasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-sword",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.parse, requests, json\n",
    "import os\n",
    "\n",
    "os.makedirs('pages')\n",
    "\n",
    "#Rescolher a informação da API pub\n",
    "for n_page in range(146):\n",
    "    main_api = 'https://gcplatform.bio.di.uminho.pt/api/pub/page/find/pubmedindexed/gastric%20cancer?page={}&size=1000&sort=string'.format(n_page)\n",
    "    address = 'lhr'\n",
    "    url = main_api + urllib.parse.urlencode({'address': address})\n",
    "    json_data = requests.get(url).json()\n",
    "\n",
    "    #Mudar o nome do ficheiro\n",
    "    filename = \"pages\\\\page_{}_gastric_cancer.json\".format(n_page)\n",
    "  \n",
    "\n",
    "    #Escrever a informação num ficheiro json\n",
    "    with open(filename, 'a') as json_file:\n",
    "        json.dump(json_data[\"content\"], json_file, indent=4, sort_keys=True) #Formata o json file, o indent e sort_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-federation",
   "metadata": {},
   "source": [
    "Por fim, foi necessário juntar todas as páginas numa única lista de objetos, ou seja, num ficheiro json com todos os objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-helicopter",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "lista=[]  \n",
    "\n",
    "files = [f for f in listdir(\"pages\") if isfile(join(\"pages\", f))]\n",
    "\n",
    "for file in files:\n",
    "    f = open('pages/'+file)\n",
    "    data = json.load(f) \n",
    "    for i in data: lista.append(i)\n",
    "    f.close()\n",
    "\n",
    "with open('info_gastric_cancer.json', 'w') as json_file:\n",
    "    json.dump(lista, json_file,indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc5fbb",
   "metadata": {},
   "source": [
    "**Converter o ficheiro json em objetos python**\n",
    "\n",
    "Inicialmente, criamos uma classe Info com quatro métodos, sendo dois os mais importantes. O primeiro método, o init, é executado quando criamos uma instância de um objeto. O segundo método, o to dict, é utilizado para converter os objetos que guardamos na lista num dicionário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-vietnam",
   "metadata": {},
   "source": [
    "Inicialmente, criamos uma classe Info com quatro métodos, sendo dois os mais importantes. O primeiro método, o init, é executado quando criamos uma instância de um objeto. O segundo método, o to dict, é utilizado para converter os objetos que guardamos na lista num dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Info:\n",
    "    def __init__(self, id=None, idGenerator=None, source=None, createdDate=None, lastModifiedDate=None, title=None, summary=None, content=None, xdbRefs=None, meshTerms=None, keywords=None):\n",
    "        self.id = id\n",
    "        self.idGenerator = idGenerator\n",
    "        self.source = source\n",
    "        self.createdDate = createdDate\n",
    "        self.lastModifiedDate = lastModifiedDate\n",
    "        self.title = title\n",
    "        self.summary = summary\n",
    "        self.content = content\n",
    "        self.xdbRefs = xdbRefs\n",
    "        self.meshTerms = meshTerms\n",
    "        self.keywords = keywords\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, json_string):\n",
    "        json_dict = json.loads(json_string)\n",
    "        return cls(**json_dict)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        #return str(self)\n",
    "        return f'{self.id}'\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'title': self.title,\n",
    "            'summary':self.summary,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-today",
   "metadata": {},
   "source": [
    "Posto isto, foi necessário ler o ficheiro json com todos os objetos e colocar esses objetos numa lista.\n",
    "\n",
    "Tendo já uma lista com os objetos é necessário colocar estes objetos num dataframe, recorrendo à biblioteca pandas.\n",
    "\n",
    "Por fim, foi exportado o dataframe para um ficheiro csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = []\n",
    "with open('info_gastric_cancer.json', 'r') as json_file:\n",
    "    info_data = json.loads(json_file.read())\n",
    "    for i in info_data: \n",
    "        info_list.append(Info(**i))\n",
    "\n",
    "df = pd.DataFrame.from_records([a.to_dict() for a in info_list])\n",
    "df.index = df[\"id\"]\n",
    "del df[\"id\"]\n",
    "\n",
    "df.to_csv('dataset_gastric_cancer.csv', sep=\",\")"
   ]
  },
  {
   "source": [
    "Agora iremos obter 50 publicações por cada sub doença através da API das publicações.\n",
    "\n",
    "Em primeiro lugar vamos obter todos os DOID, os identificadores de todas as sub doenças.\n",
    "\n",
    "De seguida obtemos a informação de cada uma das sub doenças de modo a que de seguida fosse possível obtermos as palavras chaves de cada sub doenças.\n",
    "\n",
    "Assim foi possível obter os documentos através das palavras chaves que representam as sub doenças "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_disease_pub_id(names):\n",
    "  url_request=\"https://gcplatform.bio.di.uminho.pt/api/pub/elastic/findid/content/terms?\"\n",
    "  for name in names:\n",
    "    url_request+=\"terms=\"+name+\"&\"\n",
    "  url_request+=\"page=0&size=50\"#get only 50\n",
    "  url_request = re.sub(r\"\\s+\", '%20', url_request)\n",
    "  \n",
    "  lista=[]\n",
    "  with urllib.request.urlopen(url_request) as url:  \n",
    "    pub_ids_response = json.loads(url.read().decode())\n",
    "    pub_ids=pub_ids_response[\"content\"] \n",
    "    for pub_id in pub_ids:\n",
    "        pubmed=pub_id[\"id\"].split(\":\")\n",
    "        lista.append(pubmed[1])\n",
    "    return lista    \n",
    "\n",
    "\n",
    "def get_disease_pubs(lista,disease_pub_id,doid):\n",
    "    for pubid in disease_pub_id:\n",
    "        with urllib.request.urlopen('https://gcplatform.bio.di.uminho.pt/api/pub/ids?id=pubmed%3A'+pubid) as url:  \n",
    "            pubs = json.loads(url.read().decode())\n",
    "            for pub in pubs:\n",
    "                objecto={\"doid\": doid.split(\":\")[1]}\n",
    "                if \"id\" in pub: objecto[\"id\"]=pub[\"id\"].split(\":\")[1]\n",
    "                else: objecto[\"id\"]=\"\"\n",
    "\n",
    "                if \"title\" in pub: objecto[\"title\"]=pub[\"title\"]\n",
    "                else: objecto[\"title\"]=\"\"\n",
    "                \n",
    "                if \"summary\" in pub: objecto[\"summary\"]=pub[\"summary\"]\n",
    "                else: objecto[\"summary\"]=\"\"\n",
    "\n",
    "                lista.append(objecto)\n",
    "    return lista\n",
    "\n",
    "#get all sub diseases doids\n",
    "with urllib.request.urlopen('https://gcplatform.bio.di.uminho.pt/api/dise/allsubdiseids/DOID%3A10534') as url:  \n",
    "    doids = json.loads(url.read().decode())\n",
    "    i=0\n",
    "    lista=[]\n",
    "    #iterate over all doids\n",
    "    for doid in doids:\n",
    "      id = doid.split(\":\")[1] #obter id da string \"DOID:4716\"\n",
    "      with urllib.request.urlopen('https://gcplatform.bio.di.uminho.pt/api/dise/id/DOID%3A'+id) as url_disease:\n",
    "        disease = json.loads(url_disease.read().decode())\n",
    "        names=disease[\"names\"] #get names of disease\n",
    "\n",
    "        disease_pub_id = get_disease_pub_id(names)\n",
    "        lista=get_disease_pubs(lista,disease_pub_id,doid)\n",
    "        print(i)\n",
    "        i=i+1\n",
    "\n",
    "with open('personal.json', 'w') as json_file:\n",
    "    json.dump(lista, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd0d1bf8b0d71e2aa9c2cad3c0c4e42b040e81b49fe030ef6be7f4c063ee3654c78",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "d1bf8b0d71e2aa9c2cad3c0c4e42b040e81b49fe030ef6be7f4c063ee3654c78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}